{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "from collections import defaultdict\n",
    "import pprint as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Implement the lion and cow example on a 10x10 grid (the lion's \n",
    "starting position is at the bottom left square, and the cow is in the \n",
    "top right square). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Action(Enum):\n",
    "    STAY = 0\n",
    "    NORTH = 1\n",
    "    SOUTH = 2\n",
    "    EAST = 3\n",
    "    WEST = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "reward = {\n",
    "    (1, Action.WEST) : 0,\n",
    "    (2, Action.WEST) : 0,\n",
    "    (2, Action.NORTH) : 0,\n",
    "    (2, Action.EAST) : 0,\n",
    "    (3, Action.NORTH) : 50,\n",
    "    (4, Action.NORTH) : 50,\n",
    "    (5, Action.NORTH) : 0,\n",
    "    (5, Action.EAST) : 0,\n",
    "    (6, Action.STAY) : 0,\n",
    "    (7, Action.EAST) : 100\n",
    "}\n",
    "\n",
    "transition = {\n",
    "    (1, Action.WEST) : 2,\n",
    "    (2, Action.WEST) : 3,\n",
    "    (2, Action.NORTH) : 4,\n",
    "    (2, Action.EAST) : 1,\n",
    "    (3, Action.NORTH) : 5,\n",
    "    (4, Action.NORTH) : 6,\n",
    "    (5, Action.NORTH) : 7,\n",
    "    (5, Action.EAST) : 4,\n",
    "    (6, Action.STAY) : 6,\n",
    "    (7, Action.EAST) : 6\n",
    "}\n",
    "\n",
    "state_reward = defaultdict(int)\n",
    "state_reward[5] = 50\n",
    "state_reward[6] = 100\n",
    "\n",
    "N_STATES = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "states = list(range(1, 8))\n",
    "states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "actions = {\n",
    "    1: [Action.WEST],\n",
    "    2: [Action.WEST, Action.NORTH, Action.EAST],\n",
    "    3: [Action.NORTH],\n",
    "    4: [Action.NORTH],\n",
    "    5: [Action.NORTH, Action.EAST],\n",
    "    6: [Action.STAY],\n",
    "    7: [Action.EAST]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) Compute the V* values for each state with discount factor gamma = 0.8. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def value_iteration(gamma, theta):\n",
    "    values = {}\n",
    "\n",
    "    for s in states:\n",
    "        values[s] = 0\n",
    "    niter = 0\n",
    "    while True:\n",
    "        niter += 1\n",
    "        delta = 0\n",
    "        for state in states:\n",
    "            v = values[state]\n",
    "            candidates = [r + gamma * values[ss]\n",
    "                          for a in actions[state] \n",
    "                          for ss in [transition[(state, a)]] for r in [reward[(state, a)]]]\n",
    "            values[state] = max(candidates)\n",
    "            delta = max(delta, abs(v - values[state]))\n",
    "        if delta < theta:\n",
    "            return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "values = value_iteration(gamma=0.8, theta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state      V*    \n",
      "1          72.96000000000001\n",
      "2          91.2 \n",
      "3          114.0\n",
      "4          50.0 \n",
      "5          80.0 \n",
      "6          0.0  \n",
      "7          100.0\n"
     ]
    }
   ],
   "source": [
    "print('{0: <10} {1: <6}'.format('state', 'V*'))\n",
    "for s in states:\n",
    "    print(\"{0: <10} {1: <5}\".format(s, values[s]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) What is the optimal policy when gamma = 0.8?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_policy(values):\n",
    "    policy = {}\n",
    "    for s in states:\n",
    "        pairs = [(values[transition[s,a]], a) for a in actions[s]]\n",
    "        policy[s] = sorted(pairs)[0][1]\n",
    "        \n",
    "    return policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: <Action.WEST: 4>,\n",
       " 2: <Action.NORTH: 1>,\n",
       " 3: <Action.NORTH: 1>,\n",
       " 4: <Action.NORTH: 1>,\n",
       " 5: <Action.EAST: 3>,\n",
       " 6: <Action.STAY: 0>,\n",
       " 7: <Action.EAST: 3>}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = value_iteration(gamma=0.8, theta=1)\n",
    "get_policy(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) Does the optimal policy change if gamma is set to 0.5 instead? If yes, give the new policy. If not, explain. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: <Action.WEST: 4>,\n",
       " 2: <Action.EAST: 3>,\n",
       " 3: <Action.NORTH: 1>,\n",
       " 4: <Action.NORTH: 1>,\n",
       " 5: <Action.EAST: 3>,\n",
       " 6: <Action.STAY: 0>,\n",
       " 7: <Action.EAST: 3>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = value_iteration(gamma=0.5, theta=1)\n",
    "get_policy(values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) Compute the Q(s,a) values for the following state action pairs: (S2,West), (S6,Stay), (S3, North). Let gamma = 0.8 and alpha = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Q_model_based(V_star, state, action, gamma, reward=reward, transition=transition):\n",
    "    return reward[state, action] + gamma * V_star[transition[state, action]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state      action         \n",
      "1          72.96000000000001\n",
      "2          91.2 \n",
      "3          114.0\n",
      "4          50.0 \n",
      "5          80.0 \n",
      "6          0.0  \n",
      "7          100.0\n"
     ]
    }
   ],
   "source": [
    "values = value_iteration(gamma=0.8, theta=1)\n",
    "print('{: <10} {: <15}'.format('state', 'action'))\n",
    "for s in states:\n",
    "    print(\"{0: <10} {1: <5}\".format(s, values[s]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state      action          Q  \n",
      "2          Action.WEST     91.2\n",
      "6          Action.STAY     0.0\n",
      "3          Action.NORTH    114.0\n"
     ]
    }
   ],
   "source": [
    "print('{: <10} {: <15} {: <3}'.format('state', 'action', 'Q'))\n",
    "\n",
    "for state, act in [(2, Action.WEST), (6, Action.STAY), (3, Action.NORTH)]:\n",
    "    print('{: <10} {: <15} {}'.format(state, act, Q_model_based(values, state, act, gamma=0.8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e) Consider applying the Q-learning algorithm to the \"treasure-hunting\" game. Let Q' be the estimate of Q. Initially all Q' values are set to 0, and gamma = 0.8 and alpha = 1. Assume that the agent moves from state S1, via states S2, S3, S5, and S7, to state S6. Show how the Q' values are updated during this episode. Repeat the same episode twice more and show how the Q' values are revised during each episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def init_QQ():\n",
    "    QQ = {}\n",
    "    for state in states:\n",
    "        for act in actions[state]:\n",
    "            QQ[(state, act)] = 0\n",
    "    return QQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_run(QQ, s, moves, gamma=0.8):\n",
    "    for move in moves:\n",
    "        print(\"s\", s)\n",
    "        r = reward[(s, move)]\n",
    "        print('action {}'.format(move))\n",
    "        print('reward: {}'.format(r))\n",
    "        ss = transition[s, move]\n",
    "        print('new_state: {}'.format(ss))\n",
    "        QQ[(s, move)] = r + gamma * max([QQ[(ss, a)] for a in actions[ss]])\n",
    "        pp.PrettyPrinter(indent=4).pprint(QQ)\n",
    "        print()\n",
    "        s = ss\n",
    "        \n",
    "    return QQ, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "QQ = init_QQ()\n",
    "start_state = 1\n",
    "moves = [Action.WEST, Action.WEST, Action.NORTH, Action.NORTH, Action.EAST]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s 1\n",
      "action Action.WEST\n",
      "reward: 0\n",
      "new_state: 2\n",
      "{   (1, <Action.WEST: 4>): 0.0,\n",
      "    (2, <Action.EAST: 3>): 0,\n",
      "    (2, <Action.NORTH: 1>): 0,\n",
      "    (2, <Action.WEST: 4>): 0,\n",
      "    (3, <Action.NORTH: 1>): 0,\n",
      "    (4, <Action.NORTH: 1>): 0,\n",
      "    (5, <Action.NORTH: 1>): 0,\n",
      "    (5, <Action.EAST: 3>): 0,\n",
      "    (6, <Action.STAY: 0>): 0,\n",
      "    (7, <Action.EAST: 3>): 0}\n",
      "\n",
      "s 2\n",
      "action Action.WEST\n",
      "reward: 0\n",
      "new_state: 3\n",
      "{   (1, <Action.WEST: 4>): 0.0,\n",
      "    (2, <Action.EAST: 3>): 0,\n",
      "    (2, <Action.NORTH: 1>): 0,\n",
      "    (2, <Action.WEST: 4>): 0.0,\n",
      "    (3, <Action.NORTH: 1>): 0,\n",
      "    (4, <Action.NORTH: 1>): 0,\n",
      "    (5, <Action.NORTH: 1>): 0,\n",
      "    (5, <Action.EAST: 3>): 0,\n",
      "    (6, <Action.STAY: 0>): 0,\n",
      "    (7, <Action.EAST: 3>): 0}\n",
      "\n",
      "s 3\n",
      "action Action.NORTH\n",
      "reward: 50\n",
      "new_state: 5\n",
      "{   (1, <Action.WEST: 4>): 0.0,\n",
      "    (2, <Action.EAST: 3>): 0,\n",
      "    (2, <Action.NORTH: 1>): 0,\n",
      "    (2, <Action.WEST: 4>): 0.0,\n",
      "    (3, <Action.NORTH: 1>): 50.0,\n",
      "    (4, <Action.NORTH: 1>): 0,\n",
      "    (5, <Action.NORTH: 1>): 0,\n",
      "    (5, <Action.EAST: 3>): 0,\n",
      "    (6, <Action.STAY: 0>): 0,\n",
      "    (7, <Action.EAST: 3>): 0}\n",
      "\n",
      "s 5\n",
      "action Action.NORTH\n",
      "reward: 0\n",
      "new_state: 7\n",
      "{   (1, <Action.WEST: 4>): 0.0,\n",
      "    (2, <Action.EAST: 3>): 0,\n",
      "    (2, <Action.NORTH: 1>): 0,\n",
      "    (2, <Action.WEST: 4>): 0.0,\n",
      "    (3, <Action.NORTH: 1>): 50.0,\n",
      "    (4, <Action.NORTH: 1>): 0,\n",
      "    (5, <Action.NORTH: 1>): 0.0,\n",
      "    (5, <Action.EAST: 3>): 0,\n",
      "    (6, <Action.STAY: 0>): 0,\n",
      "    (7, <Action.EAST: 3>): 0}\n",
      "\n",
      "s 7\n",
      "action Action.EAST\n",
      "reward: 100\n",
      "new_state: 6\n",
      "{   (1, <Action.WEST: 4>): 0.0,\n",
      "    (2, <Action.EAST: 3>): 0,\n",
      "    (2, <Action.NORTH: 1>): 0,\n",
      "    (2, <Action.WEST: 4>): 0.0,\n",
      "    (3, <Action.NORTH: 1>): 50.0,\n",
      "    (4, <Action.NORTH: 1>): 0,\n",
      "    (5, <Action.NORTH: 1>): 0.0,\n",
      "    (5, <Action.EAST: 3>): 0,\n",
      "    (6, <Action.STAY: 0>): 0,\n",
      "    (7, <Action.EAST: 3>): 100.0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "QQ2, s2 = one_run(QQ, start_state, moves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s 1\n",
      "action Action.WEST\n",
      "reward: 0\n",
      "new_state: 2\n",
      "{   (1, <Action.WEST: 4>): 0.0,\n",
      "    (2, <Action.EAST: 3>): 0,\n",
      "    (2, <Action.NORTH: 1>): 0,\n",
      "    (2, <Action.WEST: 4>): 0.0,\n",
      "    (3, <Action.NORTH: 1>): 50.0,\n",
      "    (4, <Action.NORTH: 1>): 0,\n",
      "    (5, <Action.NORTH: 1>): 0.0,\n",
      "    (5, <Action.EAST: 3>): 0,\n",
      "    (6, <Action.STAY: 0>): 0,\n",
      "    (7, <Action.EAST: 3>): 100.0}\n",
      "\n",
      "s 2\n",
      "action Action.WEST\n",
      "reward: 0\n",
      "new_state: 3\n",
      "{   (1, <Action.WEST: 4>): 0.0,\n",
      "    (2, <Action.EAST: 3>): 0,\n",
      "    (2, <Action.NORTH: 1>): 0,\n",
      "    (2, <Action.WEST: 4>): 40.0,\n",
      "    (3, <Action.NORTH: 1>): 50.0,\n",
      "    (4, <Action.NORTH: 1>): 0,\n",
      "    (5, <Action.NORTH: 1>): 0.0,\n",
      "    (5, <Action.EAST: 3>): 0,\n",
      "    (6, <Action.STAY: 0>): 0,\n",
      "    (7, <Action.EAST: 3>): 100.0}\n",
      "\n",
      "s 3\n",
      "action Action.NORTH\n",
      "reward: 50\n",
      "new_state: 5\n",
      "{   (1, <Action.WEST: 4>): 0.0,\n",
      "    (2, <Action.EAST: 3>): 0,\n",
      "    (2, <Action.NORTH: 1>): 0,\n",
      "    (2, <Action.WEST: 4>): 40.0,\n",
      "    (3, <Action.NORTH: 1>): 50.0,\n",
      "    (4, <Action.NORTH: 1>): 0,\n",
      "    (5, <Action.NORTH: 1>): 0.0,\n",
      "    (5, <Action.EAST: 3>): 0,\n",
      "    (6, <Action.STAY: 0>): 0,\n",
      "    (7, <Action.EAST: 3>): 100.0}\n",
      "\n",
      "s 5\n",
      "action Action.NORTH\n",
      "reward: 0\n",
      "new_state: 7\n",
      "{   (1, <Action.WEST: 4>): 0.0,\n",
      "    (2, <Action.EAST: 3>): 0,\n",
      "    (2, <Action.NORTH: 1>): 0,\n",
      "    (2, <Action.WEST: 4>): 40.0,\n",
      "    (3, <Action.NORTH: 1>): 50.0,\n",
      "    (4, <Action.NORTH: 1>): 0,\n",
      "    (5, <Action.NORTH: 1>): 80.0,\n",
      "    (5, <Action.EAST: 3>): 0,\n",
      "    (6, <Action.STAY: 0>): 0,\n",
      "    (7, <Action.EAST: 3>): 100.0}\n",
      "\n",
      "s 7\n",
      "action Action.EAST\n",
      "reward: 100\n",
      "new_state: 6\n",
      "{   (1, <Action.WEST: 4>): 0.0,\n",
      "    (2, <Action.EAST: 3>): 0,\n",
      "    (2, <Action.NORTH: 1>): 0,\n",
      "    (2, <Action.WEST: 4>): 40.0,\n",
      "    (3, <Action.NORTH: 1>): 50.0,\n",
      "    (4, <Action.NORTH: 1>): 0,\n",
      "    (5, <Action.NORTH: 1>): 80.0,\n",
      "    (5, <Action.EAST: 3>): 0,\n",
      "    (6, <Action.STAY: 0>): 0,\n",
      "    (7, <Action.EAST: 3>): 100.0}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "QQ3, s3 = one_run(QQ2, start_state, moves)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
